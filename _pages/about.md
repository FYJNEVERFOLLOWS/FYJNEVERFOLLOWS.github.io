---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


<span class='anchor' id='about-me'></span>

I study at [CCA Lab](http://cic.tju.edu.cn/faculty/wanglongbiao/labs.html) as a postgraduate now, focusing on DL-based Audio and Speech Signal Processing research. Feel free to reach me at fyjneverfollows[AT]gmail[DOT]com or fyjneverfollows[AT]163[DOT]com.

I graduated from College of [Computer Science and Technology](https://it.ouc.edu.cn/cs/main.htm), Ocean University of China with a bachelor's degree. Currently, I am pursuing a master of philosophy's degree, supervised by **[Prof. Longbiao Wang](http://cic.tju.edu.cn/faculty/wanglongbiao/wang.html)** and **[Prof. Jianwu Dang](https://scholar.google.com/citations?user=Wk5ApskAAAAJ)** at Tianjin University.

My research interest includes multi-channel speech separation and microphone array signal processing. I have published 4 papers at the top international speech and AI conferences.

<!-- I am also a contributor of the open source project, [SpeechBrain](https://github.com/speechbrain/speechbrain), working with enthusiastic members including [Mirco Ravanelli](https://sites.google.com/site/mircoravanelli/) and [Titouan Parcollet](http://www.darnault-parcollet.fr/). -->
<!-- with <a href='https://scholar.google.com/citations?&user=S4rcLewAAAAJ'><strong><span id='total_cit'>0</span></strong> total google scholar citations</a>. -->


# ğŸ”¥ News
- *2023.05*: &emsp;ğŸ‰ğŸ‰ Two papers are accepted by Interspeech 2023! 
- *2023.02*: &emsp;ğŸ‰ğŸ‰ Won [3rd place](https://www.l3das.com/icassp2023/results.html) in L3DAS23 Challenge at ICASSP 2023 with my team! 
- *2022.12*: &emsp;ğŸ‰ğŸ‰ Finished my MPhil's thesis proposal! 
- *2022.06*: &emsp;ğŸ‰ğŸ‰ Two papers are accepted by Interspeech 2022! 
- *2021.09*: &emsp;ğŸ‰ğŸ‰ Joined CCA lab formally! 
- *2021.06*: &emsp; Received my bachelor's degree from [OUC](http://www.ouc.edu.cn/main.htm)! 
- *2021.06*: &emsp; Completed my undergraduate thesis defense! 
- *2020.10*: &emsp; Admitted into *Acoustic Signal Processing & Speech Recognition Group* of CCA lab! 

# ğŸ“ Publications 

## ğŸ™ï¸ Audio and Speech Processing
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">INTERSPEECH 2023</div><img src='https://raw.githubusercontent.com/FYJNEVERFOLLOWS/Picture-Bed/main/202305/20230518170955.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Locate and Beamform: Two-dimensional Locating All-neural Beamformer for Multi-channel Speech Separation](https://arxiv.org/abs/2305.10821)

**Yanjie Fu**, Meng Ge, Honglong Wang, Nan Li, Haoran Yin, Longbiao Wang, Gaoyan Zhang, Jianwu Dang, Chengyun Deng, Fei Wang

[ğŸ“œ[paper]](https://arxiv.org/abs/2305.10821) [ğŸ’»[code]](https://github.com/FYJNEVERFOLLOWS/LaBNet)
<!-- [ğŸ“œ[paper]]() [ğŸ¬[video]](https://www.bilibili.com/video/BV1kD4y1b75n)[ğŸ“°[poster]](https://drive.google.com/file/d/1TpxvtH9qwZCaqP2NnKhQ4FAzZqJj83EM/view?usp=sharing) [ğŸ’»[code]](https://github.com/FYJNEVERFOLLOWS/LaBNet) -->
- We propose an end-to-end beamforming network for 2D location guided speech separation merely given mixture signal, estimating discriminable direction and 2D location cues, which are then integrated into location-aware neural beamformer, allowing accurate reconstruction of two sources' speech. 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">INTERSPEECH 2022</div><img src='https://raw.githubusercontent.com/FYJNEVERFOLLOWS/Picture-Bed/main/202303/20230309092122.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Iterative Sound Source Localization for Unknown Number of Sources](https://www.isca-speech.org/archive/interspeech_2022/fu22c_interspeech.html)

**Yanjie Fu**, Meng Ge, Haoran Yin, Xinyuan Qian, Longbiao Wang, Gaoyan Zhang, Jianwu Dang

[ğŸ“œ[paper]](https://www.isca-speech.org/archive/interspeech_2022/fu22c_interspeech.html) [ğŸ¬[video]](https://www.bilibili.com/video/BV1kD4y1b75n)[ğŸ“°[poster]](https://drive.google.com/file/d/1TpxvtH9qwZCaqP2NnKhQ4FAzZqJj83EM/view?usp=sharing) [ğŸ’»[code]](https://github.com/FYJNEVERFOLLOWS/ISSL)
- We propose an iterative sound source localization approach, which can deal with an arbitrary number of sources, even more than the number of sources seen during the training stage.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">L3DAS23 Challenge at ICASSP 2023</div><img src='https://raw.githubusercontent.com/FYJNEVERFOLLOWS/Picture-Bed/main/202306/20230610230932.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Stream Attention Based U-Net for L3DAS23 Challenge](https://ieeexplore.ieee.org/document/10095854)

Honglong Wang, **Yanjie Fu**, Junjie Li, Meng Ge, Longbiao Wang, Xinyuan Qian 

[ğŸ“œ[paper]](https://ieeexplore.ieee.org/document/10095854)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">INTERSPEECH 2023</div><img src='https://raw.githubusercontent.com/FYJNEVERFOLLOWS/Picture-Bed/main/202303/20230325095354.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SDNet: Stream-attention and Dual-feature Learning Network for Ad-hoc Array Speech Separation]()


Honglong Wang, Chengyun Deng, **Yanjie Fu**, Meng Ge, Longbiao Wang, Gaoyan Zhang, Jianwu Dang, Fei Wang 

[ğŸ“œ[paper]]()
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">INTERSPEECH 2022</div><img src='https://raw.githubusercontent.com/FYJNEVERFOLLOWS/Picture-Bed/main/202303/20230325184210.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MIMO-DoAnet: Multi-channel Input and Multiple Outputs DoA Network with Unknown Number of Sound Sources](https://www.isca-speech.org/archive/interspeech_2022/yin22b_interspeech.html)

Haoran Yin, Meng Ge, **Yanjie Fu**, Gaoyan Zhang, Longbiao Wang, Lei Zhang, Lin Qiu, Jianwu Dang

[ğŸ“œ[paper]](https://www.isca-speech.org/archive/interspeech_2022/yin22b_interspeech.html)[ğŸ“°[poster]](https://drive.google.com/file/d/1bTSSorgCL5C4chIGBAmC3Y4nZ6S0-uht/view?usp=sharing) [ğŸ’»[code]](https://github.com/TJU-haoran/VCTK-16k-simulated)
</div>
</div>

## ğŸŒªï¸ Computational Meteorology
- [Establishing a Cyclone Generator to Study the Rotation and Advance Characteristics of Tornadoes](https://meetingorganizer.copernicus.org/EGU2020/EGU2020-2372.html), Yuanzhuo Zeng, **Yanjie Fu**, and Chenglin Lyu, EGU General Assembly 2020 [ğŸ“œ[paper]](https://meetingorganizer.copernicus.org/EGU2020/EGU2020-2372.html) 


# ğŸ… Honors and Awards
- *2022.12* &emsp; [Kiyoshi Honda](https://ieeexplore.ieee.org/author/37076528200) Speech Science Scholarship, [CCA Lab](http://cic.tju.edu.cn/faculty/wanglongbiao/labs.html), Tianjin University. 
- *2021.06* &emsp; Outstanding Graduate of Shandong Province (Top 5%), Department of Education of Shandong Province. 
- *2020.12* &emsp; National Scholarship (Undergraduate) (Top 1%), Ministry of Education of the People's Republic of China.  
- *2020.08* &emsp; Third Prize in Entrepreneurship Practice in the 11th China College Students Service Outsourcing Innovation and Entrepreneurship Competition, Ministry of Education of the People's Republic of China, Ministry of Commerce of the People's Republic of China and Wuxi Municipal People's Government.  
- *2019.09* &emsp; Silver Award in the 5th Shandong Province "Internet+" College Students Innovation and Entrepreneurship Competition, Department of Education of Shandong Province. 


# ğŸ‘¨â€ğŸ“ Education
- *2021.09 - 2024.01 (now)*, Master of Philosophy, Tianjin Key Laboratory of Cognitive Computing and Application, College of Intelligence and Computing, Tianjin University, Tianjin. 
- *2017.09 - 2021.06*, Bachelor, College of Computer Science and Technology, Ocean University of China, Qingdao. 

<!-- # ğŸ’¬ Invited Talks 
- *2021.03*, .  \| [\[video\]](https://github.com/) -->

# ğŸ“– Teaching Experiences
- Teaching Assistant, Speech Information Processing (2021 Autumn, 2022 Autumn).

# ğŸ’¼ Internships
- *2021.06 - 2021.09*, [Willing Technology](https://www.weiling.cn/), Shanghai.
- *2021.03 - 2021.06*, [Anzhi Capital](https://www.anzhicapital.com/), Qingdao.

# ğŸ’¯ Certifications
- IELTS: 7.5 &emsp; 2020.08

<center>
    <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=gQjO4hHduemuAibbLx1mm69deVzeCKRbLOGaDaL5eoU&cl=ffffff&w=a"></script>
    <br> &copy; Yanjie Fu | Last updated: May 18th, 2023 | Theme by Yi Ren
</center>